{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(([2,9], [1,5], [3,6]), dtype=torch.float)\n",
    "y = torch.tensor(([92],[100], [89]), dtype=torch.float)\n",
    "xPredicted = torch.tensor(([4,8]), dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2])\n",
      "torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "print(X.size())\n",
    "print(y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_max, _ = torch.max(X,0)\n",
    "xPredicted_max, _ = torch.max(xPredicted, 0)\n",
    "X = torch.div(X, X_max)\n",
    "xPredicted = torch.div(xPredicted, xPredicted_max)\n",
    "y = y / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Network(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(Neural_Network, self).__init__()\n",
    "        self.inputSize = 2\n",
    "        self.outputSize = 1\n",
    "        self.hiddenSize = 3\n",
    "        \n",
    "        \n",
    "        self.W1 = torch.randn(self.inputSize, self.hiddenSize)\n",
    "        self.W2 = torch.randn(self.hiddenSize, self.outputSize)\n",
    "\n",
    "        \n",
    "    def forward(self, X):\n",
    "        self.z = torch.matmul(X, self.W1)\n",
    "        self.z2 = self.sigmoid(self.z)\n",
    "        self.z3 = torch.matmul(self.z2, self.W2)\n",
    "        o = self.sigmoid(self.z3)\n",
    "        return o\n",
    "    \n",
    "    \n",
    "    def sigmoid(self, s):\n",
    "        return 1 / (1 + torch.exp(-s))\n",
    "    \n",
    "    \n",
    "    def sigmoidPrime(self, s):\n",
    "        return s * (1 - s)\n",
    "    \n",
    "    \n",
    "    def backward(self, X, y, o):\n",
    "        self.o_error = y - o\n",
    "        self.o_delta = self.o_error\n",
    "        self.z2_error = torch.matmul(self.o_delta, torch.t(self.W2))\n",
    "        self.z2_delta = self.z2_error * self.sigmoidPrime(self.z2)\n",
    "        self.W1 += torch.matmul(torch.t(X), self.z2_delta)\n",
    "        self.W2 += torch.matmul(torch.t(self.z2), self.o_delta)\n",
    "        \n",
    "    \n",
    "    def train(self, X, y):\n",
    "        o = self.forward(X)\n",
    "        self.backward(X, y, o)\n",
    "        \n",
    "        \n",
    "    def saveWeights(self, model):\n",
    "        torch.save(model, \"NN\")\n",
    "        \n",
    "        \n",
    "    def predict(self):\n",
    "        print(\"Predicted data is: \")\n",
    "        print(\"Input (scaled): \\n\" + str(xPredicted))\n",
    "        print(\"Output: \\n\" + str(self.forward(xPredicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0 Loss: 0.13324378430843353\n",
      "#1 Loss: 0.07420293241739273\n",
      "#2 Loss: 0.039182569831609726\n",
      "#3 Loss: 0.020225826650857925\n",
      "#4 Loss: 0.011168934404850006\n",
      "#5 Loss: 0.0070596425794065\n",
      "#6 Loss: 0.0051534478552639484\n",
      "#7 Loss: 0.004215733148157597\n",
      "#8 Loss: 0.0037210474256426096\n",
      "#9 Loss: 0.003440587781369686\n",
      "#10 Loss: 0.003269621403887868\n",
      "#11 Loss: 0.0031574759632349014\n",
      "#12 Loss: 0.003078339621424675\n",
      "#13 Loss: 0.0030184369534254074\n",
      "#14 Loss: 0.0029701117891818285\n",
      "#15 Loss: 0.0029289554804563522\n",
      "#16 Loss: 0.002892346354201436\n",
      "#17 Loss: 0.0028586771804839373\n",
      "#18 Loss: 0.0028269358444958925\n",
      "#19 Loss: 0.002796491840854287\n",
      "#20 Loss: 0.0027669016271829605\n",
      "#21 Loss: 0.0027378955855965614\n",
      "#22 Loss: 0.00270928000099957\n",
      "#23 Loss: 0.0026809312403202057\n",
      "#24 Loss: 0.0026527626905590296\n",
      "#25 Loss: 0.002624713582918048\n",
      "#26 Loss: 0.0025967515539377928\n",
      "#27 Loss: 0.0025688353925943375\n",
      "#28 Loss: 0.0025409702211618423\n",
      "#29 Loss: 0.002513142069801688\n",
      "#30 Loss: 0.002485338831320405\n",
      "#31 Loss: 0.002457559807226062\n",
      "#32 Loss: 0.0024298145435750484\n",
      "#33 Loss: 0.0024021028075367212\n",
      "#34 Loss: 0.0023744350764900446\n",
      "#35 Loss: 0.002346805762499571\n",
      "#36 Loss: 0.002319233724847436\n",
      "#37 Loss: 0.002291720127686858\n",
      "#38 Loss: 0.0022642759140580893\n",
      "#39 Loss: 0.0022369029466062784\n",
      "#40 Loss: 0.002209615893661976\n",
      "#41 Loss: 0.0021824210416525602\n",
      "#42 Loss: 0.0021553225815296173\n",
      "#43 Loss: 0.0021283349487930536\n",
      "#44 Loss: 0.002101458376273513\n",
      "#45 Loss: 0.0020747026428580284\n",
      "#46 Loss: 0.0020480824168771505\n",
      "#47 Loss: 0.002021603984758258\n",
      "#48 Loss: 0.001995271071791649\n",
      "#49 Loss: 0.0019690862391144037\n",
      "#50 Loss: 0.0019430667161941528\n",
      "#51 Loss: 0.0019172182073816657\n",
      "#52 Loss: 0.001891541643999517\n",
      "#53 Loss: 0.001866048201918602\n",
      "#54 Loss: 0.0018407466122880578\n",
      "#55 Loss: 0.0018156360602006316\n",
      "#56 Loss: 0.001790727605111897\n",
      "#57 Loss: 0.0017660275334492326\n",
      "#58 Loss: 0.001741535495966673\n",
      "#59 Loss: 0.0017172688385471702\n",
      "#60 Loss: 0.0016932195285335183\n",
      "#61 Loss: 0.0016694042133167386\n",
      "#62 Loss: 0.0016458169557154179\n",
      "#63 Loss: 0.0016224688151851296\n",
      "#64 Loss: 0.001599361770786345\n",
      "#65 Loss: 0.0015764989657327533\n",
      "#66 Loss: 0.0015538918087258935\n",
      "#67 Loss: 0.0015315301716327667\n",
      "#68 Loss: 0.001509424764662981\n",
      "#69 Loss: 0.0014875790802761912\n",
      "#70 Loss: 0.0014659975422546268\n",
      "#71 Loss: 0.001444674446247518\n",
      "#72 Loss: 0.0014236178249120712\n",
      "#73 Loss: 0.0014028254663571715\n",
      "#74 Loss: 0.0013823057524859905\n",
      "#75 Loss: 0.001362057402729988\n",
      "#76 Loss: 0.0013420722680166364\n",
      "#77 Loss: 0.0013223645510151982\n",
      "#78 Loss: 0.0013029292458668351\n",
      "#79 Loss: 0.0012837640242651105\n",
      "#80 Loss: 0.0012648754054680467\n",
      "#81 Loss: 0.0012462574522942305\n",
      "#82 Loss: 0.0012279119109734893\n",
      "#83 Loss: 0.0012098402949050069\n",
      "#84 Loss: 0.0011920372489839792\n",
      "#85 Loss: 0.0011745095252990723\n",
      "#86 Loss: 0.0011572468793019652\n",
      "#87 Loss: 0.0011402568779885769\n",
      "#88 Loss: 0.001123533002100885\n",
      "#89 Loss: 0.001107078162021935\n",
      "#90 Loss: 0.0010908840922638774\n",
      "#91 Loss: 0.001074952189810574\n",
      "#92 Loss: 0.0010592848993837833\n",
      "#93 Loss: 0.0010438732570037246\n",
      "#94 Loss: 0.0010287220356985927\n",
      "#95 Loss: 0.0010138223879039288\n",
      "#96 Loss: 0.000999178271740675\n",
      "#97 Loss: 0.0009847864275798202\n",
      "#98 Loss: 0.0009706351556815207\n",
      "#99 Loss: 0.0009567379020154476\n",
      "#100 Loss: 0.0009430767968297005\n",
      "#101 Loss: 0.000929659407120198\n",
      "#102 Loss: 0.0009164779330603778\n",
      "#103 Loss: 0.0009035306866280735\n",
      "#104 Loss: 0.0008908169693313539\n",
      "#105 Loss: 0.0008783270604908466\n",
      "#106 Loss: 0.0008660675375722349\n",
      "#107 Loss: 0.0008540302515029907\n",
      "#108 Loss: 0.0008422136306762695\n",
      "#109 Loss: 0.0008306148811243474\n",
      "#110 Loss: 0.0008192278328351676\n",
      "#111 Loss: 0.00080805056495592\n",
      "#112 Loss: 0.0007970843580551445\n",
      "#113 Loss: 0.0007863239734433591\n",
      "#114 Loss: 0.0007757612620480359\n",
      "#115 Loss: 0.0007654023356735706\n",
      "#116 Loss: 0.000755235378164798\n",
      "#117 Loss: 0.0007452610298059881\n",
      "#118 Loss: 0.0007354768458753824\n",
      "#119 Loss: 0.0007258826517499983\n",
      "#120 Loss: 0.0007164672133512795\n",
      "#121 Loss: 0.0007072330918163061\n",
      "#122 Loss: 0.0006981780752539635\n",
      "#123 Loss: 0.000689296517521143\n",
      "#124 Loss: 0.0006805842858739197\n",
      "#125 Loss: 0.0006720439996570349\n",
      "#126 Loss: 0.000663668557535857\n",
      "#127 Loss: 0.0006554534193128347\n",
      "#128 Loss: 0.0006473999819718301\n",
      "#129 Loss: 0.0006395024829544127\n",
      "#130 Loss: 0.0006317596998997033\n",
      "#131 Loss: 0.0006241685478016734\n",
      "#132 Loss: 0.000616724428255111\n",
      "#133 Loss: 0.0006094268173910677\n",
      "#134 Loss: 0.0006022701854817569\n",
      "#135 Loss: 0.0005952561623416841\n",
      "#136 Loss: 0.0005883798003196716\n",
      "#137 Loss: 0.000581637374125421\n",
      "#138 Loss: 0.0005750256823375821\n",
      "#139 Loss: 0.0005685472278855741\n",
      "#140 Loss: 0.0005621933378279209\n",
      "#141 Loss: 0.0005559656419791281\n",
      "#142 Loss: 0.0005498622194863856\n",
      "#143 Loss: 0.0005438760854303837\n",
      "#144 Loss: 0.0005380090442486107\n",
      "#145 Loss: 0.00053225620649755\n",
      "#146 Loss: 0.0005266189109534025\n",
      "#147 Loss: 0.0005210899980738759\n",
      "#148 Loss: 0.0005156696424819529\n",
      "#149 Loss: 0.0005103565054014325\n",
      "#150 Loss: 0.0005051458138041198\n",
      "#151 Loss: 0.0005000407109037042\n",
      "#152 Loss: 0.000495033513288945\n",
      "#153 Loss: 0.0004901245119981468\n",
      "#154 Loss: 0.0004853121645282954\n",
      "#155 Loss: 0.0004805928037967533\n",
      "#156 Loss: 0.0004759643052238971\n",
      "#157 Loss: 0.0004714255628641695\n",
      "#158 Loss: 0.00046697771176695824\n",
      "#159 Loss: 0.00046261551324278116\n",
      "#160 Loss: 0.0004583356494549662\n",
      "#161 Loss: 0.0004541403613984585\n",
      "#162 Loss: 0.00045002545812167227\n",
      "#163 Loss: 0.0004459907941054553\n",
      "#164 Loss: 0.0004420327313710004\n",
      "#165 Loss: 0.0004381516482681036\n",
      "#166 Loss: 0.00043434242252260447\n",
      "#167 Loss: 0.00043061046744696796\n",
      "#168 Loss: 0.0004269470227882266\n",
      "#169 Loss: 0.0004233520303387195\n",
      "#170 Loss: 0.0004198266251478344\n",
      "#171 Loss: 0.00041636647074483335\n",
      "#172 Loss: 0.0004129738954361528\n",
      "#173 Loss: 0.0004096440097782761\n",
      "#174 Loss: 0.00040637809433974326\n",
      "#175 Loss: 0.0004031733551528305\n",
      "#176 Loss: 0.0004000237677246332\n",
      "#177 Loss: 0.0003969371609855443\n",
      "#178 Loss: 0.00039390751044265926\n",
      "#179 Loss: 0.00039093117811717093\n",
      "#180 Loss: 0.0003880141593981534\n",
      "#181 Loss: 0.00038514778134413064\n",
      "#182 Loss: 0.0003823331499006599\n",
      "#183 Loss: 0.00037957020686008036\n",
      "#184 Loss: 0.00037685621646232903\n",
      "#185 Loss: 0.00037419365253299475\n",
      "#186 Loss: 0.00037157931365072727\n",
      "#187 Loss: 0.0003690100566018373\n",
      "#188 Loss: 0.0003664859395939857\n",
      "#189 Loss: 0.00036400716635398567\n",
      "#190 Loss: 0.0003615734167397022\n",
      "#191 Loss: 0.00035917965578846633\n",
      "#192 Loss: 0.00035683062742464244\n",
      "#193 Loss: 0.000354521645931527\n",
      "#194 Loss: 0.00035225265310145915\n",
      "#195 Loss: 0.0003500240854918957\n",
      "#196 Loss: 0.00034783288720063865\n",
      "#197 Loss: 0.0003456775739323348\n",
      "#198 Loss: 0.00034356137621216476\n",
      "#199 Loss: 0.0003414774255361408\n",
      "#200 Loss: 0.0003394325904082507\n",
      "#201 Loss: 0.0003374194202478975\n",
      "#202 Loss: 0.0003354416985530406\n",
      "#203 Loss: 0.00033349436125718057\n",
      "#204 Loss: 0.0003315800568088889\n",
      "#205 Loss: 0.00032969730091281235\n",
      "#206 Loss: 0.0003278445510659367\n",
      "#207 Loss: 0.00032602137071080506\n",
      "#208 Loss: 0.0003242285456508398\n",
      "#209 Loss: 0.0003224644169677049\n",
      "#210 Loss: 0.00032072613248601556\n",
      "#211 Loss: 0.00031901642796583474\n",
      "#212 Loss: 0.0003173327131662518\n",
      "#213 Loss: 0.0003156747843604535\n",
      "#214 Loss: 0.0003140434855595231\n",
      "#215 Loss: 0.00031243686680682003\n",
      "#216 Loss: 0.0003108545788563788\n",
      "#217 Loss: 0.00030929435160942376\n",
      "#218 Loss: 0.00030775988125242293\n",
      "#219 Loss: 0.00030624610371887684\n",
      "#220 Loss: 0.0003047562204301357\n",
      "#221 Loss: 0.00030328668071888387\n",
      "#222 Loss: 0.0003018389397766441\n",
      "#223 Loss: 0.000300410931231454\n",
      "#224 Loss: 0.00029900623485445976\n",
      "#225 Loss: 0.0002976184186991304\n",
      "#226 Loss: 0.0002962515864055604\n",
      "#227 Loss: 0.0002949026820715517\n",
      "#228 Loss: 0.0002935723168775439\n",
      "#229 Loss: 0.0002922605781350285\n",
      "#230 Loss: 0.00029096726211719215\n",
      "#231 Loss: 0.00028968966216780245\n",
      "#232 Loss: 0.0002884325513150543\n",
      "#233 Loss: 0.0002871876931749284\n",
      "#234 Loss: 0.000285960704786703\n",
      "#235 Loss: 0.00028474946157075465\n",
      "#236 Loss: 0.00028355384711176157\n",
      "#237 Loss: 0.00028237421065568924\n",
      "#238 Loss: 0.000281207641819492\n",
      "#239 Loss: 0.0002800558868329972\n",
      "#240 Loss: 0.00027891798526979983\n",
      "#241 Loss: 0.00027779696392826736\n",
      "#242 Loss: 0.000276685954304412\n",
      "#243 Loss: 0.0002755900495685637\n",
      "#244 Loss: 0.00027450642664916813\n",
      "#245 Loss: 0.0002734360168687999\n",
      "#246 Loss: 0.0002723769284784794\n",
      "#247 Loss: 0.0002713305875658989\n",
      "#248 Loss: 0.0002702972269617021\n",
      "#249 Loss: 0.00026927347062155604\n",
      "#250 Loss: 0.0002682619378902018\n",
      "#251 Loss: 0.00026726259966380894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#252 Loss: 0.00026627248735167086\n",
      "#253 Loss: 0.00026529384194873273\n",
      "#254 Loss: 0.00026432552840560675\n",
      "#255 Loss: 0.0002633662079460919\n",
      "#256 Loss: 0.0002624189655762166\n",
      "#257 Loss: 0.0002614796394482255\n",
      "#258 Loss: 0.0002605506160762161\n",
      "#259 Loss: 0.00025962977088056505\n",
      "#260 Loss: 0.0002587202179711312\n",
      "#261 Loss: 0.00025781788281165063\n",
      "#262 Loss: 0.00025692550116218626\n",
      "#263 Loss: 0.00025603981339372694\n",
      "#264 Loss: 0.000255164981354028\n",
      "#265 Loss: 0.0002542968431953341\n",
      "#266 Loss: 0.0002534359518904239\n",
      "#267 Loss: 0.00025258524692617357\n",
      "#268 Loss: 0.0002517412358429283\n",
      "#269 Loss: 0.00025090371491387486\n",
      "#270 Loss: 0.0002500742848496884\n",
      "#271 Loss: 0.00024925413890741765\n",
      "#272 Loss: 0.0002484378928784281\n",
      "#273 Loss: 0.00024763119290582836\n",
      "#274 Loss: 0.00024682917864993215\n",
      "#275 Loss: 0.00024603467318229377\n",
      "#276 Loss: 0.00024524738546460867\n",
      "#277 Loss: 0.00024446460884064436\n",
      "#278 Loss: 0.0002436897630104795\n",
      "#279 Loss: 0.00024292117450386286\n",
      "#280 Loss: 0.00024215773737523705\n",
      "#281 Loss: 0.00024140246387105435\n",
      "#282 Loss: 0.00024064908211585134\n",
      "#283 Loss: 0.0002399052755208686\n",
      "#284 Loss: 0.00023916592181194574\n",
      "#285 Loss: 0.00023842958034947515\n",
      "#286 Loss: 0.00023770093685016036\n",
      "#287 Loss: 0.00023697807046119124\n",
      "#288 Loss: 0.00023625872563570738\n",
      "#289 Loss: 0.00023554438666906208\n",
      "#290 Loss: 0.00023483742552343756\n",
      "#291 Loss: 0.00023413314193021506\n",
      "#292 Loss: 0.00023343427164945751\n",
      "#293 Loss: 0.0002327414695173502\n",
      "#294 Loss: 0.00023204932222142816\n",
      "#295 Loss: 0.0002313665027031675\n",
      "#296 Loss: 0.00023068541486281902\n",
      "#297 Loss: 0.00023000955116003752\n",
      "#298 Loss: 0.0002293370052939281\n",
      "#299 Loss: 0.0002286699746036902\n",
      "#300 Loss: 0.00022800710576120764\n",
      "#301 Loss: 0.00022734637605026364\n",
      "#302 Loss: 0.0002266922383569181\n",
      "#303 Loss: 0.00022604106925427914\n",
      "#304 Loss: 0.00022539244673680514\n",
      "#305 Loss: 0.0002247502707177773\n",
      "#306 Loss: 0.00022411055397242308\n",
      "#307 Loss: 0.00022347339836414903\n",
      "#308 Loss: 0.00022284085571300238\n",
      "#309 Loss: 0.00022221273684408516\n",
      "#310 Loss: 0.0002215870190411806\n",
      "#311 Loss: 0.00022096636530477554\n",
      "#312 Loss: 0.00022034694848116487\n",
      "#313 Loss: 0.00021973233378957957\n",
      "#314 Loss: 0.0002191197854699567\n",
      "#315 Loss: 0.00021851070050615817\n",
      "#316 Loss: 0.00021790493337903172\n",
      "#317 Loss: 0.00021730373555328697\n",
      "#318 Loss: 0.00021670387650374323\n",
      "#319 Loss: 0.00021610804833471775\n",
      "#320 Loss: 0.00021551466488745064\n",
      "#321 Loss: 0.00021492416271939874\n",
      "#322 Loss: 0.0002143383026123047\n",
      "#323 Loss: 0.00021375280630309135\n",
      "#324 Loss: 0.00021317275241017342\n",
      "#325 Loss: 0.00021259282948449254\n",
      "#326 Loss: 0.00021201843628659844\n",
      "#327 Loss: 0.00021144404308870435\n",
      "#328 Loss: 0.00021087504865135998\n",
      "#329 Loss: 0.00021030736388638616\n",
      "#330 Loss: 0.0002097423275699839\n",
      "#331 Loss: 0.00020917884830851108\n",
      "#332 Loss: 0.00020862033125013113\n",
      "#333 Loss: 0.00020806374959647655\n",
      "#334 Loss: 0.00020750756084453315\n",
      "#335 Loss: 0.00020695563580375165\n",
      "#336 Loss: 0.00020640534057747573\n",
      "#337 Loss: 0.000205858945264481\n",
      "#338 Loss: 0.0002053124480880797\n",
      "#339 Loss: 0.00020477002544794232\n",
      "#340 Loss: 0.00020423038222361356\n",
      "#341 Loss: 0.00020369216508697718\n",
      "#342 Loss: 0.00020315621804911643\n",
      "#343 Loss: 0.0002026237634709105\n",
      "#344 Loss: 0.00020209135254845023\n",
      "#345 Loss: 0.0002015624922933057\n",
      "#346 Loss: 0.00020103731367271394\n",
      "#347 Loss: 0.00020051095634698868\n",
      "#348 Loss: 0.00019998928473796695\n",
      "#349 Loss: 0.00019946927204728127\n",
      "#350 Loss: 0.0001989497832255438\n",
      "#351 Loss: 0.00019843502377625555\n",
      "#352 Loss: 0.00019792019156739116\n",
      "#353 Loss: 0.00019740824063774198\n",
      "#354 Loss: 0.00019689742475748062\n",
      "#355 Loss: 0.00019639142556115985\n",
      "#356 Loss: 0.00019588375289458781\n",
      "#357 Loss: 0.00019537883053999394\n",
      "#358 Loss: 0.000194877153262496\n",
      "#359 Loss: 0.00019437777518760413\n",
      "#360 Loss: 0.00019388047803658992\n",
      "#361 Loss: 0.00019338347192388028\n",
      "#362 Loss: 0.0001928889541886747\n",
      "#363 Loss: 0.00019239580433350056\n",
      "#364 Loss: 0.00019190624880138785\n",
      "#365 Loss: 0.00019141763914376497\n",
      "#366 Loss: 0.0001909297425299883\n",
      "#367 Loss: 0.00019044411601498723\n",
      "#368 Loss: 0.00018996089056599885\n",
      "#369 Loss: 0.0001894786983029917\n",
      "#370 Loss: 0.00018899959104601294\n",
      "#371 Loss: 0.00018852118228096515\n",
      "#372 Loss: 0.0001880444324342534\n",
      "#373 Loss: 0.00018757021462079138\n",
      "#374 Loss: 0.00018709692812990397\n",
      "#375 Loss: 0.00018662567890714854\n",
      "#376 Loss: 0.00018615646695252508\n",
      "#377 Loss: 0.00018568865198176354\n",
      "#378 Loss: 0.00018522220489103347\n",
      "#379 Loss: 0.0001847578096203506\n",
      "#380 Loss: 0.00018429434567224234\n",
      "#381 Loss: 0.000183833806659095\n",
      "#382 Loss: 0.0001833742717280984\n",
      "#383 Loss: 0.00018291595915798098\n",
      "#384 Loss: 0.00018246103718411177\n",
      "#385 Loss: 0.00018200476188212633\n",
      "#386 Loss: 0.00018155296857003123\n",
      "#387 Loss: 0.00018110063683707267\n",
      "#388 Loss: 0.00018065032782033086\n",
      "#389 Loss: 0.00018020247807726264\n",
      "#390 Loss: 0.0001797553850337863\n",
      "#391 Loss: 0.00017931022739503533\n",
      "#392 Loss: 0.0001788667286746204\n",
      "#393 Loss: 0.0001784247433533892\n",
      "#394 Loss: 0.00017798396584112197\n",
      "#395 Loss: 0.00017754452710505575\n",
      "#396 Loss: 0.00017710687825456262\n",
      "#397 Loss: 0.00017667109204921871\n",
      "#398 Loss: 0.00017623644089326262\n",
      "#399 Loss: 0.00017580314306542277\n",
      "#400 Loss: 0.00017537239182274789\n",
      "#401 Loss: 0.00017494217900093645\n",
      "#402 Loss: 0.00017451238818466663\n",
      "#403 Loss: 0.00017408537678420544\n",
      "#404 Loss: 0.00017366062093060464\n",
      "#405 Loss: 0.00017323519568890333\n",
      "#406 Loss: 0.00017281346663367003\n",
      "#407 Loss: 0.00017239102453459054\n",
      "#408 Loss: 0.00017197082343045622\n",
      "#409 Loss: 0.00017155281966552138\n",
      "#410 Loss: 0.00017113564535975456\n",
      "#411 Loss: 0.00017071864567697048\n",
      "#412 Loss: 0.000170306462678127\n",
      "#413 Loss: 0.00016989234427455813\n",
      "#414 Loss: 0.00016948037955444306\n",
      "#415 Loss: 0.00016907094686757773\n",
      "#416 Loss: 0.00016866215446498245\n",
      "#417 Loss: 0.00016825349302962422\n",
      "#418 Loss: 0.00016784768376965076\n",
      "#419 Loss: 0.00016744389722589403\n",
      "#420 Loss: 0.00016703885921742767\n",
      "#421 Loss: 0.00016663760470692068\n",
      "#422 Loss: 0.00016623716510366648\n",
      "#423 Loss: 0.00016583730757702142\n",
      "#424 Loss: 0.00016544068057555705\n",
      "#425 Loss: 0.00016504291852470487\n",
      "#426 Loss: 0.0001646470045670867\n",
      "#427 Loss: 0.00016425458306912333\n",
      "#428 Loss: 0.0001638608518987894\n",
      "#429 Loss: 0.00016347014752682298\n",
      "#430 Loss: 0.00016307964688166976\n",
      "#431 Loss: 0.00016269167826976627\n",
      "#432 Loss: 0.00016230354958679527\n",
      "#433 Loss: 0.00016191699251066893\n",
      "#434 Loss: 0.0001615321234567091\n",
      "#435 Loss: 0.00016114891332108527\n",
      "#436 Loss: 0.00016076621250249445\n",
      "#437 Loss: 0.00016038537432905287\n",
      "#438 Loss: 0.0001600058312760666\n",
      "#439 Loss: 0.00015962684119585901\n",
      "#440 Loss: 0.00015924956824164838\n",
      "#441 Loss: 0.00015887324116192758\n",
      "#442 Loss: 0.00015849924238864332\n",
      "#443 Loss: 0.00015812461788300425\n",
      "#444 Loss: 0.0001577533403178677\n",
      "#445 Loss: 0.00015738180081825703\n",
      "#446 Loss: 0.00015701126540079713\n",
      "#447 Loss: 0.00015664314560126513\n",
      "#448 Loss: 0.0001562764373375103\n",
      "#449 Loss: 0.00015590952534694225\n",
      "#450 Loss: 0.0001555443595862016\n",
      "#451 Loss: 0.00015518149302806705\n",
      "#452 Loss: 0.00015481823356822133\n",
      "#453 Loss: 0.00015445782628376037\n",
      "#454 Loss: 0.00015409676416311413\n",
      "#455 Loss: 0.0001537371426820755\n",
      "#456 Loss: 0.0001533793256385252\n",
      "#457 Loss: 0.00015302360407076776\n",
      "#458 Loss: 0.00015266871196217835\n",
      "#459 Loss: 0.00015231440193019807\n",
      "#460 Loss: 0.00015196170716080815\n",
      "#461 Loss: 0.00015160981274675578\n",
      "#462 Loss: 0.00015125896607059985\n",
      "#463 Loss: 0.00015090916713234037\n",
      "#464 Loss: 0.00015056035772431642\n",
      "#465 Loss: 0.00015021422586869448\n",
      "#466 Loss: 0.00014986867608968168\n",
      "#467 Loss: 0.00014952254423405975\n",
      "#468 Loss: 0.00014917945372872055\n",
      "#469 Loss: 0.0001488355192122981\n",
      "#470 Loss: 0.00014849477156531066\n",
      "#471 Loss: 0.0001481539657106623\n",
      "#472 Loss: 0.00014781591016799212\n",
      "#473 Loss: 0.00014747750537935644\n",
      "#474 Loss: 0.0001471395225962624\n",
      "#475 Loss: 0.00014680472668260336\n",
      "#476 Loss: 0.00014646923227701336\n",
      "#477 Loss: 0.0001461364736314863\n",
      "#478 Loss: 0.00014580290007870644\n",
      "#479 Loss: 0.00014547150931321084\n",
      "#480 Loss: 0.00014514104987028986\n",
      "#481 Loss: 0.0001448120310669765\n",
      "#482 Loss: 0.00014448432193603367\n",
      "#483 Loss: 0.00014415728219319135\n",
      "#484 Loss: 0.0001438304752809927\n",
      "#485 Loss: 0.00014350659330375493\n",
      "#486 Loss: 0.00014318143075797707\n",
      "#487 Loss: 0.00014286043005995452\n",
      "#488 Loss: 0.0001425380032742396\n",
      "#489 Loss: 0.0001422170316800475\n",
      "#490 Loss: 0.0001418974861735478\n",
      "#491 Loss: 0.00014158012345433235\n",
      "#492 Loss: 0.00014126191672403365\n",
      "#493 Loss: 0.00014094582002144307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#494 Loss: 0.0001406300434609875\n",
      "#495 Loss: 0.00014031676982995123\n",
      "#496 Loss: 0.00014000236114952713\n",
      "#497 Loss: 0.00013969084830023348\n",
      "#498 Loss: 0.0001393782440572977\n",
      "#499 Loss: 0.00013906984531786293\n",
      "#500 Loss: 0.00013876006414648145\n",
      "#501 Loss: 0.00013845184003002942\n",
      "#502 Loss: 0.0001381454203510657\n",
      "#503 Loss: 0.00013783997565042228\n",
      "#504 Loss: 0.00013753330858889967\n",
      "#505 Loss: 0.0001372301921946928\n",
      "#506 Loss: 0.00013692703214474022\n",
      "#507 Loss: 0.00013662467245012522\n",
      "#508 Loss: 0.00013632391346618533\n",
      "#509 Loss: 0.00013602437684312463\n",
      "#510 Loss: 0.00013572456373367459\n",
      "#511 Loss: 0.00013542747183237225\n",
      "#512 Loss: 0.00013512899749912322\n",
      "#513 Loss: 0.00013483302609529346\n",
      "#514 Loss: 0.00013453808787744492\n",
      "#515 Loss: 0.00013424483768176287\n",
      "#516 Loss: 0.00013395115092862397\n",
      "#517 Loss: 0.00013365925406105816\n",
      "#518 Loss: 0.00013336814299691468\n",
      "#519 Loss: 0.00013307739573065192\n",
      "#520 Loss: 0.00013278824917506427\n",
      "#521 Loss: 0.00013249983021523803\n",
      "#522 Loss: 0.00013221219705883414\n",
      "#523 Loss: 0.00013192612095735967\n",
      "#524 Loss: 0.00013164036499802023\n",
      "#525 Loss: 0.0001313553802901879\n",
      "#526 Loss: 0.00013107228733133525\n",
      "#527 Loss: 0.00013078963092993945\n",
      "#528 Loss: 0.00013050778943579644\n",
      "#529 Loss: 0.00013022797065787017\n",
      "#530 Loss: 0.00012994714779779315\n",
      "#531 Loss: 0.00012966792564839125\n",
      "#532 Loss: 0.0001293905806960538\n",
      "#533 Loss: 0.00012911293015349656\n",
      "#534 Loss: 0.00012883661838714033\n",
      "#535 Loss: 0.00012856147077400237\n",
      "#536 Loss: 0.00012828684702981263\n",
      "#537 Loss: 0.00012801481352653354\n",
      "#538 Loss: 0.00012774083006661385\n",
      "#539 Loss: 0.00012746990250889212\n",
      "#540 Loss: 0.00012719880032818764\n",
      "#541 Loss: 0.0001269277126993984\n",
      "#542 Loss: 0.00012665994290728122\n",
      "#543 Loss: 0.0001263915910385549\n",
      "#544 Loss: 0.0001261237484868616\n",
      "#545 Loss: 0.00012585741933435202\n",
      "#546 Loss: 0.0001255926035810262\n",
      "#547 Loss: 0.00012532777327578515\n",
      "#548 Loss: 0.0001250642817467451\n",
      "#549 Loss: 0.0001248009648406878\n",
      "#550 Loss: 0.00012453865201678127\n",
      "#551 Loss: 0.0001242769358213991\n",
      "#552 Loss: 0.00012401783897075802\n",
      "#553 Loss: 0.00012375843652989715\n",
      "#554 Loss: 0.00012349979078862816\n",
      "#555 Loss: 0.00012324082490522414\n",
      "#556 Loss: 0.00012298488582018763\n",
      "#557 Loss: 0.00012272881576791406\n",
      "#558 Loss: 0.00012247324048075825\n",
      "#559 Loss: 0.0001222181599587202\n",
      "#560 Loss: 0.00012196486204629764\n",
      "#561 Loss: 0.00012171352136647329\n",
      "#562 Loss: 0.00012146073277108371\n",
      "#563 Loss: 0.00012120979954488575\n",
      "#564 Loss: 0.00012095967394998297\n",
      "#565 Loss: 0.00012070926459273323\n",
      "#566 Loss: 0.00012046095071127638\n",
      "#567 Loss: 0.00012021364091197029\n",
      "#568 Loss: 0.000119965618068818\n",
      "#569 Loss: 0.00011971953063039109\n",
      "#570 Loss: 0.00011947363236686215\n",
      "#571 Loss: 0.00011922956764465198\n",
      "#572 Loss: 0.00011898628872586414\n",
      "#573 Loss: 0.00011874207848450169\n",
      "#574 Loss: 0.00011850054579554126\n",
      "#575 Loss: 0.00011825894034700468\n",
      "#576 Loss: 0.0001180176914203912\n",
      "#577 Loss: 0.00011777792678913102\n",
      "#578 Loss: 0.0001175391735159792\n",
      "#579 Loss: 0.00011730024561984465\n",
      "#580 Loss: 0.00011706217628670856\n",
      "#581 Loss: 0.00011682591866701841\n",
      "#582 Loss: 0.00011659032315947115\n",
      "#583 Loss: 0.00011635510600171983\n",
      "#584 Loss: 0.00011612049274845049\n",
      "#585 Loss: 0.00011588720371946692\n",
      "#586 Loss: 0.00011565356544451788\n",
      "#587 Loss: 0.00011542191350599751\n",
      "#588 Loss: 0.00011518935207277536\n",
      "#589 Loss: 0.00011495916987769306\n",
      "#590 Loss: 0.00011472905316622928\n",
      "#591 Loss: 0.00011450032616266981\n",
      "#592 Loss: 0.00011427138815633953\n",
      "#593 Loss: 0.000114043039502576\n",
      "#594 Loss: 0.00011381559306755662\n",
      "#595 Loss: 0.00011358886695234105\n",
      "#596 Loss: 0.00011336425814079121\n",
      "#597 Loss: 0.00011313959112158045\n",
      "#598 Loss: 0.0001129150259657763\n",
      "#599 Loss: 0.00011269127571722493\n",
      "#600 Loss: 0.00011246878420934081\n",
      "#601 Loss: 0.00011224640911677852\n",
      "#602 Loss: 0.0001120247834478505\n",
      "#603 Loss: 0.0001118045111070387\n",
      "#604 Loss: 0.00011158429697388783\n",
      "#605 Loss: 0.00011136505781905726\n",
      "#606 Loss: 0.00011114688822999597\n",
      "#607 Loss: 0.00011092858039774\n",
      "#608 Loss: 0.00011071180779254064\n",
      "#609 Loss: 0.00011049534077756107\n",
      "#610 Loss: 0.00011027962318621576\n",
      "#611 Loss: 0.00011006407294189557\n",
      "#612 Loss: 0.00010984990512952209\n",
      "#613 Loss: 0.00010963680688291788\n",
      "#614 Loss: 0.0001094235121854581\n",
      "#615 Loss: 0.00010921087232418358\n",
      "#616 Loss: 0.00010899887274717912\n",
      "#617 Loss: 0.00010878814646275714\n",
      "#618 Loss: 0.00010857830784516409\n",
      "#619 Loss: 0.00010836846195161343\n",
      "#620 Loss: 0.0001081584268831648\n",
      "#621 Loss: 0.0001079502108041197\n",
      "#622 Loss: 0.00010774354450404644\n",
      "#623 Loss: 0.00010753609240055084\n",
      "#624 Loss: 0.0001073300009011291\n",
      "#625 Loss: 0.00010712441871874034\n",
      "#626 Loss: 0.00010691865463741124\n",
      "#627 Loss: 0.00010671451309463009\n",
      "#628 Loss: 0.00010651073534972966\n",
      "#629 Loss: 0.00010630746692186221\n",
      "#630 Loss: 0.00010610487515805289\n",
      "#631 Loss: 0.00010590359306661412\n",
      "#632 Loss: 0.00010570162703515962\n",
      "#633 Loss: 0.00010550072329351678\n",
      "#634 Loss: 0.00010530098370509222\n",
      "#635 Loss: 0.00010510252468520775\n",
      "#636 Loss: 0.00010490315617062151\n",
      "#637 Loss: 0.0001047050827764906\n",
      "#638 Loss: 0.00010450708214193583\n",
      "#639 Loss: 0.0001043103402480483\n",
      "#640 Loss: 0.00010411479888716713\n",
      "#641 Loss: 0.00010391796240583062\n",
      "#642 Loss: 0.00010372366523370147\n",
      "#643 Loss: 0.00010352825484005734\n",
      "#644 Loss: 0.00010333487443858758\n",
      "#645 Loss: 0.0001031423089443706\n",
      "#646 Loss: 0.00010294894309481606\n",
      "#647 Loss: 0.00010275713430019096\n",
      "#648 Loss: 0.00010256589303025976\n",
      "#649 Loss: 0.00010237417882308364\n",
      "#650 Loss: 0.00010218392708338797\n",
      "#651 Loss: 0.0001019942355924286\n",
      "#652 Loss: 0.00010180578829022124\n",
      "#653 Loss: 0.00010161628597415984\n",
      "#654 Loss: 0.00010142819519387558\n",
      "#655 Loss: 0.00010124086838914081\n",
      "#656 Loss: 0.00010105411638505757\n",
      "#657 Loss: 0.00010086804832099006\n",
      "#658 Loss: 0.00010068258416140452\n",
      "#659 Loss: 0.00010049695265479386\n",
      "#660 Loss: 0.00010031299461843446\n",
      "#661 Loss: 0.00010012910206569359\n",
      "#662 Loss: 9.994547144742683e-05\n",
      "#663 Loss: 9.976187720894814e-05\n",
      "#664 Loss: 9.95805676211603e-05\n",
      "#665 Loss: 9.939831215888262e-05\n",
      "#666 Loss: 9.921676246449351e-05\n",
      "#667 Loss: 9.903734462568536e-05\n",
      "#668 Loss: 9.885719191515818e-05\n",
      "#669 Loss: 9.867743938229978e-05\n",
      "#670 Loss: 9.849770140135661e-05\n",
      "#671 Loss: 9.832024807110429e-05\n",
      "#672 Loss: 9.814314398681745e-05\n",
      "#673 Loss: 9.796473750611767e-05\n",
      "#674 Loss: 9.778848470887169e-05\n",
      "#675 Loss: 9.76112496573478e-05\n",
      "#676 Loss: 9.743574628373608e-05\n",
      "#677 Loss: 9.72608759184368e-05\n",
      "#678 Loss: 9.708603465696797e-05\n",
      "#679 Loss: 9.691164450487122e-05\n",
      "#680 Loss: 9.673916065366939e-05\n",
      "#681 Loss: 9.656584734329954e-05\n",
      "#682 Loss: 9.639276686357334e-05\n",
      "#683 Loss: 9.622067591408268e-05\n",
      "#684 Loss: 9.604950901120901e-05\n",
      "#685 Loss: 9.587771637598053e-05\n",
      "#686 Loss: 9.570715337758884e-05\n",
      "#687 Loss: 9.553720155963674e-05\n",
      "#688 Loss: 9.536799188936129e-05\n",
      "#689 Loss: 9.519977174932137e-05\n",
      "#690 Loss: 9.503026376478374e-05\n",
      "#691 Loss: 9.486338967690244e-05\n",
      "#692 Loss: 9.469606447964907e-05\n",
      "#693 Loss: 9.452813537791371e-05\n",
      "#694 Loss: 9.436247637495399e-05\n",
      "#695 Loss: 9.419624257134274e-05\n",
      "#696 Loss: 9.402966679772362e-05\n",
      "#697 Loss: 9.386503370478749e-05\n",
      "#698 Loss: 9.37009826884605e-05\n",
      "#699 Loss: 9.35367206693627e-05\n",
      "#700 Loss: 9.337308438261971e-05\n",
      "#701 Loss: 9.321083052782342e-05\n",
      "#702 Loss: 9.304802370024845e-05\n",
      "#703 Loss: 9.288531146012247e-05\n",
      "#704 Loss: 9.272358875023201e-05\n",
      "#705 Loss: 9.256204793928191e-05\n",
      "#706 Loss: 9.240161307388917e-05\n",
      "#707 Loss: 9.22417311812751e-05\n",
      "#708 Loss: 9.208260598825291e-05\n",
      "#709 Loss: 9.192304423777387e-05\n",
      "#710 Loss: 9.176356979878619e-05\n",
      "#711 Loss: 9.160568151855841e-05\n",
      "#712 Loss: 9.144757495960221e-05\n",
      "#713 Loss: 9.128948295256123e-05\n",
      "#714 Loss: 9.113348642131314e-05\n",
      "#715 Loss: 9.097662405110896e-05\n",
      "#716 Loss: 9.082089673029259e-05\n",
      "#717 Loss: 9.066488564712927e-05\n",
      "#718 Loss: 9.05098786461167e-05\n",
      "#719 Loss: 9.035494440468028e-05\n",
      "#720 Loss: 9.020159632200375e-05\n",
      "#721 Loss: 9.004745515994728e-05\n",
      "#722 Loss: 8.98942889762111e-05\n",
      "#723 Loss: 8.974099910119548e-05\n",
      "#724 Loss: 8.958910621004179e-05\n",
      "#725 Loss: 8.943689317675307e-05\n",
      "#726 Loss: 8.928574243327603e-05\n",
      "#727 Loss: 8.91342424438335e-05\n",
      "#728 Loss: 8.898330270312726e-05\n",
      "#729 Loss: 8.883315604180098e-05\n",
      "#730 Loss: 8.868376608006656e-05\n",
      "#731 Loss: 8.853426697896793e-05\n",
      "#732 Loss: 8.838524809107184e-05\n",
      "#733 Loss: 8.823688403936103e-05\n",
      "#734 Loss: 8.808813436189666e-05\n",
      "#735 Loss: 8.794144378043711e-05\n",
      "#736 Loss: 8.779426570981741e-05\n",
      "#737 Loss: 8.764690574025735e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#738 Loss: 8.750004781177267e-05\n",
      "#739 Loss: 8.735514711588621e-05\n",
      "#740 Loss: 8.720860205357894e-05\n",
      "#741 Loss: 8.706346852704883e-05\n",
      "#742 Loss: 8.691847324371338e-05\n",
      "#743 Loss: 8.67742346599698e-05\n",
      "#744 Loss: 8.663093467475846e-05\n",
      "#745 Loss: 8.648717630421743e-05\n",
      "#746 Loss: 8.634358528070152e-05\n",
      "#747 Loss: 8.620149310445413e-05\n",
      "#748 Loss: 8.605828043073416e-05\n",
      "#749 Loss: 8.59169231262058e-05\n",
      "#750 Loss: 8.577474363846704e-05\n",
      "#751 Loss: 8.563407027395442e-05\n",
      "#752 Loss: 8.549392077839002e-05\n",
      "#753 Loss: 8.535396045772359e-05\n",
      "#754 Loss: 8.521317067788914e-05\n",
      "#755 Loss: 8.507435995852575e-05\n",
      "#756 Loss: 8.493466884829104e-05\n",
      "#757 Loss: 8.479572716169059e-05\n",
      "#758 Loss: 8.465797873213887e-05\n",
      "#759 Loss: 8.451968460576609e-05\n",
      "#760 Loss: 8.438237273367122e-05\n",
      "#761 Loss: 8.424473344348371e-05\n",
      "#762 Loss: 8.410841837758198e-05\n",
      "#763 Loss: 8.397187775699422e-05\n",
      "#764 Loss: 8.383677777601406e-05\n",
      "#765 Loss: 8.370044088223949e-05\n",
      "#766 Loss: 8.35654282127507e-05\n",
      "#767 Loss: 8.342991350218654e-05\n",
      "#768 Loss: 8.329476258950308e-05\n",
      "#769 Loss: 8.316028834087774e-05\n",
      "#770 Loss: 8.302725473186001e-05\n",
      "#771 Loss: 8.289425750263035e-05\n",
      "#772 Loss: 8.276094013126567e-05\n",
      "#773 Loss: 8.262900519184768e-05\n",
      "#774 Loss: 8.249497477663681e-05\n",
      "#775 Loss: 8.236339635914192e-05\n",
      "#776 Loss: 8.223184704547748e-05\n",
      "#777 Loss: 8.210137457353994e-05\n",
      "#778 Loss: 8.197039278456941e-05\n",
      "#779 Loss: 8.183919271687046e-05\n",
      "#780 Loss: 8.170904038706794e-05\n",
      "#781 Loss: 8.157934644259512e-05\n",
      "#782 Loss: 8.144982712110505e-05\n",
      "#783 Loss: 8.132038055919111e-05\n",
      "#784 Loss: 8.119238918880001e-05\n",
      "#785 Loss: 8.106443419819698e-05\n",
      "#786 Loss: 8.09360935818404e-05\n",
      "#787 Loss: 8.080808765953407e-05\n",
      "#788 Loss: 8.068120951065794e-05\n",
      "#789 Loss: 8.055385842453688e-05\n",
      "#790 Loss: 8.042631088756025e-05\n",
      "#791 Loss: 8.030089520616457e-05\n",
      "#792 Loss: 8.01750211394392e-05\n",
      "#793 Loss: 8.004916890058666e-05\n",
      "#794 Loss: 7.992451719474047e-05\n",
      "#795 Loss: 7.979962538229302e-05\n",
      "#796 Loss: 7.967428973643109e-05\n",
      "#797 Loss: 7.954981265356764e-05\n",
      "#798 Loss: 7.942623778944835e-05\n",
      "#799 Loss: 7.930291030788794e-05\n",
      "#800 Loss: 7.917994662420824e-05\n",
      "#801 Loss: 7.905675010988489e-05\n",
      "#802 Loss: 7.893355359556153e-05\n",
      "#803 Loss: 7.881061901571229e-05\n",
      "#804 Loss: 7.868988177506253e-05\n",
      "#805 Loss: 7.856795855332166e-05\n",
      "#806 Loss: 7.84472722443752e-05\n",
      "#807 Loss: 7.832560368115082e-05\n",
      "#808 Loss: 7.820517203072086e-05\n",
      "#809 Loss: 7.808452210156247e-05\n",
      "#810 Loss: 7.796516001690179e-05\n",
      "#811 Loss: 7.784469926264137e-05\n",
      "#812 Loss: 7.772559183649719e-05\n",
      "#813 Loss: 7.760707376291975e-05\n",
      "#814 Loss: 7.748802454443648e-05\n",
      "#815 Loss: 7.736928091617301e-05\n",
      "#816 Loss: 7.725136674707755e-05\n",
      "#817 Loss: 7.71336563047953e-05\n",
      "#818 Loss: 7.701634604018182e-05\n",
      "#819 Loss: 7.689829362789169e-05\n",
      "#820 Loss: 7.678167457925156e-05\n",
      "#821 Loss: 7.666511373827234e-05\n",
      "#822 Loss: 7.654954242752865e-05\n",
      "#823 Loss: 7.643309072591364e-05\n",
      "#824 Loss: 7.631689368281513e-05\n",
      "#825 Loss: 7.620200631208718e-05\n",
      "#826 Loss: 7.608709711348638e-05\n",
      "#827 Loss: 7.597244257340208e-05\n",
      "#828 Loss: 7.585781713714823e-05\n",
      "#829 Loss: 7.57435554987751e-05\n",
      "#830 Loss: 7.563053077319637e-05\n",
      "#831 Loss: 7.551609451184049e-05\n",
      "#832 Loss: 7.540309161413461e-05\n",
      "#833 Loss: 7.529056892963126e-05\n",
      "#834 Loss: 7.517689664382488e-05\n",
      "#835 Loss: 7.506540714530274e-05\n",
      "#836 Loss: 7.495315367123112e-05\n",
      "#837 Loss: 7.484028901671991e-05\n",
      "#838 Loss: 7.472949073417112e-05\n",
      "#839 Loss: 7.461829227395356e-05\n",
      "#840 Loss: 7.450729026459157e-05\n",
      "#841 Loss: 7.439631008310243e-05\n",
      "#842 Loss: 7.428634125972167e-05\n",
      "#843 Loss: 7.417595043079928e-05\n",
      "#844 Loss: 7.40669493097812e-05\n",
      "#845 Loss: 7.395717693725601e-05\n",
      "#846 Loss: 7.384792115772143e-05\n",
      "#847 Loss: 7.373831613222137e-05\n",
      "#848 Loss: 7.36296278773807e-05\n",
      "#849 Loss: 7.352178363362327e-05\n",
      "#850 Loss: 7.341346645262092e-05\n",
      "#851 Loss: 7.330581865971908e-05\n",
      "#852 Loss: 7.319820724660531e-05\n",
      "#853 Loss: 7.30912433937192e-05\n",
      "#854 Loss: 7.298391574295238e-05\n",
      "#855 Loss: 7.287704647751525e-05\n",
      "#856 Loss: 7.277071563294157e-05\n",
      "#857 Loss: 7.266407192219049e-05\n",
      "#858 Loss: 7.25587087799795e-05\n",
      "#859 Loss: 7.245215238071978e-05\n",
      "#860 Loss: 7.23475095583126e-05\n",
      "#861 Loss: 7.224235741887242e-05\n",
      "#862 Loss: 7.2136775997933e-05\n",
      "#863 Loss: 7.203275890788063e-05\n",
      "#864 Loss: 7.192830526037142e-05\n",
      "#865 Loss: 7.182385888881981e-05\n",
      "#866 Loss: 7.171967445174232e-05\n",
      "#867 Loss: 7.161702524172142e-05\n",
      "#868 Loss: 7.151338650146499e-05\n",
      "#869 Loss: 7.141081732697785e-05\n",
      "#870 Loss: 7.130770973162726e-05\n",
      "#871 Loss: 7.120464579202235e-05\n",
      "#872 Loss: 7.110242586350068e-05\n",
      "#873 Loss: 7.100033690221608e-05\n",
      "#874 Loss: 7.089910650392994e-05\n",
      "#875 Loss: 7.079801434883848e-05\n",
      "#876 Loss: 7.069698767736554e-05\n",
      "#877 Loss: 7.059591735014692e-05\n",
      "#878 Loss: 7.049462146824226e-05\n",
      "#879 Loss: 7.039420597720891e-05\n",
      "#880 Loss: 7.029431435512379e-05\n",
      "#881 Loss: 7.019432086963207e-05\n",
      "#882 Loss: 7.009457476669922e-05\n",
      "#883 Loss: 6.9994835939724e-05\n",
      "#884 Loss: 6.989573739701882e-05\n",
      "#885 Loss: 6.979566387599334e-05\n",
      "#886 Loss: 6.969703827053308e-05\n",
      "#887 Loss: 6.959887105040252e-05\n",
      "#888 Loss: 6.950110400794074e-05\n",
      "#889 Loss: 6.940263119759038e-05\n",
      "#890 Loss: 6.930466770427302e-05\n",
      "#891 Loss: 6.920751911820844e-05\n",
      "#892 Loss: 6.910964293638244e-05\n",
      "#893 Loss: 6.901356391608715e-05\n",
      "#894 Loss: 6.89162770868279e-05\n",
      "#895 Loss: 6.881901936139911e-05\n",
      "#896 Loss: 6.872353696962819e-05\n",
      "#897 Loss: 6.862682494102046e-05\n",
      "#898 Loss: 6.85310733388178e-05\n",
      "#899 Loss: 6.843567825853825e-05\n",
      "#900 Loss: 6.833970110164955e-05\n",
      "#901 Loss: 6.82448735460639e-05\n",
      "#902 Loss: 6.815016240580007e-05\n",
      "#903 Loss: 6.805473822169006e-05\n",
      "#904 Loss: 6.796015804866329e-05\n",
      "#905 Loss: 6.786570156691596e-05\n",
      "#906 Loss: 6.777203088859096e-05\n",
      "#907 Loss: 6.767802551621571e-05\n",
      "#908 Loss: 6.758502422599122e-05\n",
      "#909 Loss: 6.74915499985218e-05\n",
      "#910 Loss: 6.73985414323397e-05\n",
      "#911 Loss: 6.730525637976825e-05\n",
      "#912 Loss: 6.721285899402574e-05\n",
      "#913 Loss: 6.711971218464896e-05\n",
      "#914 Loss: 6.702781683998182e-05\n",
      "#915 Loss: 6.693599425489083e-05\n",
      "#916 Loss: 6.68434367980808e-05\n",
      "#917 Loss: 6.675211625406519e-05\n",
      "#918 Loss: 6.666126864729449e-05\n",
      "#919 Loss: 6.656924961134791e-05\n",
      "#920 Loss: 6.647865666309372e-05\n",
      "#921 Loss: 6.638799823122099e-05\n",
      "#922 Loss: 6.629780546063557e-05\n",
      "#923 Loss: 6.620765634579584e-05\n",
      "#924 Loss: 6.611757999053225e-05\n",
      "#925 Loss: 6.602763460250571e-05\n",
      "#926 Loss: 6.593728176085278e-05\n",
      "#927 Loss: 6.584783841390163e-05\n",
      "#928 Loss: 6.57591808703728e-05\n",
      "#929 Loss: 6.566995580215007e-05\n",
      "#930 Loss: 6.558067252626643e-05\n",
      "#931 Loss: 6.54922187095508e-05\n",
      "#932 Loss: 6.540392496390268e-05\n",
      "#933 Loss: 6.531552935484797e-05\n",
      "#934 Loss: 6.522735202452168e-05\n",
      "#935 Loss: 6.513999687740579e-05\n",
      "#936 Loss: 6.505219789687544e-05\n",
      "#937 Loss: 6.496460264315829e-05\n",
      "#938 Loss: 6.487778591690585e-05\n",
      "#939 Loss: 6.479110015789047e-05\n",
      "#940 Loss: 6.470354128396139e-05\n",
      "#941 Loss: 6.461729935836047e-05\n",
      "#942 Loss: 6.45307736704126e-05\n",
      "#943 Loss: 6.444513564929366e-05\n",
      "#944 Loss: 6.435935210902244e-05\n",
      "#945 Loss: 6.427339394576848e-05\n",
      "#946 Loss: 6.418780685635284e-05\n",
      "#947 Loss: 6.410280911950395e-05\n",
      "#948 Loss: 6.401651626219973e-05\n",
      "#949 Loss: 6.393194780685008e-05\n",
      "#950 Loss: 6.384777225321159e-05\n",
      "#951 Loss: 6.376293458743021e-05\n",
      "#952 Loss: 6.367860623868182e-05\n",
      "#953 Loss: 6.35942051303573e-05\n",
      "#954 Loss: 6.351030606310815e-05\n",
      "#955 Loss: 6.342680717352778e-05\n",
      "#956 Loss: 6.334338104352355e-05\n",
      "#957 Loss: 6.325970753096044e-05\n",
      "#958 Loss: 6.317648512776941e-05\n",
      "#959 Loss: 6.309395394055173e-05\n",
      "#960 Loss: 6.301117537077516e-05\n",
      "#961 Loss: 6.292838224908337e-05\n",
      "#962 Loss: 6.284577102633193e-05\n",
      "#963 Loss: 6.276358180912212e-05\n",
      "#964 Loss: 6.268137803999707e-05\n",
      "#965 Loss: 6.259930523810908e-05\n",
      "#966 Loss: 6.251793820410967e-05\n",
      "#967 Loss: 6.243595998967066e-05\n",
      "#968 Loss: 6.235556793399155e-05\n",
      "#969 Loss: 6.227364065125585e-05\n",
      "#970 Loss: 6.219260831130669e-05\n",
      "#971 Loss: 6.211199070094153e-05\n",
      "#972 Loss: 6.203144585015252e-05\n",
      "#973 Loss: 6.195082823978737e-05\n",
      "#974 Loss: 6.187005783431232e-05\n",
      "#975 Loss: 6.179081537993625e-05\n",
      "#976 Loss: 6.171083805384114e-05\n",
      "#977 Loss: 6.163120997371152e-05\n",
      "#978 Loss: 6.155133451102301e-05\n",
      "#979 Loss: 6.147230305941775e-05\n",
      "#980 Loss: 6.139367906143889e-05\n",
      "#981 Loss: 6.13139636698179e-05\n",
      "#982 Loss: 6.123519415268674e-05\n",
      "#983 Loss: 6.11570940236561e-05\n",
      "#984 Loss: 6.10787101322785e-05\n",
      "#985 Loss: 6.1000337154837325e-05\n",
      "#986 Loss: 6.092201510909945e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#987 Loss: 6.084376946091652e-05\n",
      "#988 Loss: 6.0766320530092344e-05\n",
      "#989 Loss: 6.0688926168950275e-05\n",
      "#990 Loss: 6.0611546359723434e-05\n",
      "#991 Loss: 6.053436663933098e-05\n",
      "#992 Loss: 6.045749250915833e-05\n",
      "#993 Loss: 6.038065839675255e-05\n",
      "#994 Loss: 6.030361691955477e-05\n",
      "#995 Loss: 6.022725938237272e-05\n",
      "#996 Loss: 6.015021062921733e-05\n",
      "#997 Loss: 6.00751482124906e-05\n",
      "#998 Loss: 5.9998928918503225e-05\n",
      "#999 Loss: 5.992289516143501e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\egebyas\\AppData\\Local\\conda\\conda\\envs\\py37\\lib\\site-packages\\torch\\serialization.py:256: UserWarning: Couldn't retrieve source code for container of type Neural_Network. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted data is: \n",
      "Input (scaled): \n",
      "tensor([0.5000, 1.0000])\n",
      "Output: \n",
      "tensor([0.9578])\n"
     ]
    }
   ],
   "source": [
    "NN = Neural_Network()\n",
    "for i in range(1000):\n",
    "    print (\"#\" + str(i) + \" Loss: \" + str(torch.mean((y - NN(X))**2).detach().item()))\n",
    "    NN.train(X, y)\n",
    "NN.saveWeights(NN)\n",
    "NN.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
